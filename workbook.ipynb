{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init, set our service principal credz and load a local image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"photo-manager-proto-97c81b37f3da.json\" \n",
    "\n",
    "from google.cloud import vision\n",
    "\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "file_path = os.path.abspath('christer.jpg')\n",
    "\n",
    "# Loads the image into memory\n",
    "with io.open(file_path, 'rb') as image_file:\n",
    "    image_content = image_file.read()\n",
    "\n",
    "image = vision.Image(content=image_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safe_search_annotation {\n",
      "  adult: VERY_UNLIKELY\n",
      "  spoof: UNLIKELY\n",
      "  medical: VERY_UNLIKELY\n",
      "  violence: VERY_UNLIKELY\n",
      "  racy: VERY_UNLIKELY\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.safe_search_detection(image=image)\n",
    "safe = response.safe_search_annotation\n",
    "print(response)\n",
    "print(safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.label_detection(image=image)\n",
    "print(response)\n",
    "# labels = response.label_annotations\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Landmarks:')\n",
    "response = client.landmark_detection(image=image)\n",
    "print(response)\n",
    "landmarks = response.landmark_annotations\n",
    "\n",
    "for landmark in landmarks:\n",
    "    print(landmark.description)\n",
    "    for location in landmark.locations:\n",
    "        lat_lng = location.lat_lng\n",
    "        print('Latitude {}'.format(lat_lng.latitude))\n",
    "        print('Longitude {}'.format(lat_lng.longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.face_detection(image=image)\n",
    "faces = response.face_annotations\n",
    "# print(response) printing faces or the response seem to output prettu mush the the same thing\n",
    "# print(faces)\n",
    "\n",
    "for i, face in enumerate(faces):\n",
    "    print()\n",
    "    vertices = ([f'({vertex.x},{vertex.y})' for vertex in face.bounding_poly.vertices]) # fd_bounding_poly?...\n",
    "    print(f'Face #{i}, bounds: {\", \".join(vertices)}')\n",
    "    print()\n",
    "    print(face)\n",
    "    # for mark in face.landmarks:\n",
    "    #     print(f'{mark.type_}({mark.position.x},{mark.position.y},{mark.position.z})')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9dc8ab893de1eeb12238bd5f8a3522e0060b35d78747c82dd5784a806ff3da8c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('venvw': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
